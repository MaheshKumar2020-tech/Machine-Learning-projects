{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The CIFAR-10 dataset is comprised of 60,000 32Ã—32 pixel color photographs of objects from 10 classes, such as frogs, birds, cats, ships, etc. The class labels and their standard associated integer values are listed below.\n",
    "\n",
    "0: airplane, 1: automobile, 2: bird, 3: cat, 4: deer, 5: dog, 6: frog, 7: horse, 8: ship, 9: truck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "from keras.datasets import cifar10\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = keras.datasets.cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'keras.datasets.cifar10' from 'c:\\\\users\\\\mahesh kumar m r\\\\anaconda3\\\\envs\\\\tensorflow\\\\lib\\\\site-packages\\\\keras\\\\datasets\\\\cifar10.py'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "    (X_train_full, y_train_full), (X_test, y_test) = cifar10.load_data()\n",
    "    # one hot encode target values\n",
    "    y_train_full = keras.utils.to_categorical(y_train_full)\n",
    "    y_test = keras.utils.to_categorical(y_test)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
    "    return X_train, X_valid, X_test, y_train, y_valid, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the pixels 0-1\n",
    "def scale_pixels(train, valid, test):\n",
    "    # cast from int to float\n",
    "    X_train_norm = train.astype('float32')\n",
    "    X_valid_norm = valid.astype('float32')\n",
    "    X_test_norm = test.astype('float32')\n",
    "    # normalize the pixels to 0-1\n",
    "    X_train_norm = X_train_norm / 255.0\n",
    "    X_valid_norm = X_valid_norm / 255.0\n",
    "    X_test_norm = X_test_norm / 255.0\n",
    "    return X_train_norm, X_valid_norm, X_test_norm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model - Model1 - one VGG block\n",
    "def define_baseline_model1():\n",
    "    model1 = Sequential()\n",
    "    model1.add(Conv2D(32, (3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same', input_shape=(32,32,3)))\n",
    "    model1.add(Conv2D(32, (3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
    "    model1.add(MaxPooling2D(2,2))\n",
    "    model1.add(Flatten())\n",
    "    model1.add(Dense(128, activation = 'relu', kernel_initializer='he_uniform'))\n",
    "    model1.add(Dense(10, activation = 'softmax'))\n",
    "    # compile the model\n",
    "    opt = keras.optimizers.Adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999)\n",
    "    model1.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model - Model2 - two VGG block\n",
    "def define_baseline_model2():\n",
    "    model2 = Sequential()\n",
    "    model2.add(Conv2D(32, (3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same', input_shape = (32, 32, 3)))\n",
    "    model2.add(Conv2D(32, (3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
    "    model2.add(MaxPooling2D(2,2))\n",
    "    model2.add(Conv2D(64, (3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
    "    model2.add(Conv2D(64, (3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
    "    model2.add(MaxPooling2D(2,2))\n",
    "    model2.add(Flatten())\n",
    "    model2.add(Dense(128, activation = 'relu', kernel_initializer = 'he_uniform'))\n",
    "    model2.add(Dense(10, activation = 'softmax'))\n",
    "    # compile the model\n",
    "    opt = keras.optimizers.Adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999)\n",
    "    model2.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model - Model3 - three VGG block\n",
    "def define_baseline_model3():\n",
    "    model3 = Sequential()\n",
    "    model3.add(Conv2D(32, (3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same', input_shape = (32, 32, 3)))\n",
    "    model3.add(Conv2D(32, (3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
    "    model3.add(MaxPooling2D(2,2))\n",
    "    model3.add(Conv2D(64, (3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
    "    model3.add(Conv2D(64, (3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
    "    model3.add(MaxPooling2D(2,2))\n",
    "    model3.add(Conv2D(128, (3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
    "    model3.add(Conv2D(128, (3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
    "    model3.add(MaxPooling2D(2,2))\n",
    "    model3.add(Flatten())\n",
    "    model3.add(Dense(128, activation = 'relu', kernel_initializer = 'he_uniform'))\n",
    "    model3.add(Dense(10, activation = 'softmax'))\n",
    "    # compile the model\n",
    "    opt = keras.optimizers.Adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999)\n",
    "    model3.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model - Model4 - three VGG block with dropout\n",
    "def define_baseline_model4():\n",
    "    model4 = Sequential()\n",
    "    model4.add(Conv2D(32, (3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same', input_shape = (32, 32, 3)))\n",
    "    model4.add(Conv2D(32, (3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
    "    model4.add(MaxPooling2D(2,2))\n",
    "    model4.add(Dropout(0.2))\n",
    "    model4.add(Conv2D(64, (3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
    "    model4.add(Conv2D(64, (3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
    "    model4.add(MaxPooling2D(2,2))\n",
    "    model4.add(Dropout(0.2))\n",
    "    model4.add(Conv2D(128, (3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
    "    model4.add(Conv2D(128, (3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
    "    model4.add(MaxPooling2D(2,2))\n",
    "    model4.add(Dropout(0.2))\n",
    "    model4.add(Flatten())\n",
    "    model4.add(Dense(128, activation = 'relu', kernel_initializer = 'he_uniform'))\n",
    "    model4.add(Dropout(0.2))\n",
    "    model4.add(Dense(10, activation = 'softmax'))\n",
    "    # compile the model\n",
    "    opt = keras.optimizers.Adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999)\n",
    "    model4.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return model4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model - Model5 - three VGG block with dropout and weight decay / regularization\n",
    "def define_baseline_model5():\n",
    "    model5 = Sequential()\n",
    "    model5.add(Conv2D(32, (3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same', kernel_regularizer = l2(0.001), input_shape = (32, 32, 3)))\n",
    "    model5.add(Conv2D(32, (3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same', kernel_regularizer = l2(0.001)))\n",
    "    model5.add(MaxPooling2D(2,2))\n",
    "    model5.add(Dropout(0.2))\n",
    "    model5.add(Conv2D(64, (3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same', kernel_regularizer = l2(0.001)))\n",
    "    model5.add(Conv2D(64, (3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same', kernel_regularizer = l2(0.001)))\n",
    "    model5.add(MaxPooling2D(2,2))\n",
    "    model5.add(Dropout(0.3))\n",
    "    model5.add(Conv2D(128, (3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same', kernel_regularizer = l2(0.001)))\n",
    "    model5.add(Conv2D(128, (3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same', kernel_regularizer = l2(0.001)))\n",
    "    model5.add(MaxPooling2D(2,2))\n",
    "    model5.add(Dropout(0.4))\n",
    "    model5.add(Flatten())\n",
    "    model5.add(Dense(128, activation = 'relu', kernel_initializer = 'he_uniform', kernel_regularizer = l2(0.001)))\n",
    "    model5.add(Dropout(0.5))\n",
    "    model5.add(Dense(10, activation = 'softmax'))\n",
    "    # compile the model\n",
    "    opt = keras.optimizers.Adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999)\n",
    "    model5.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return model5\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model - Model6 - three VGG block with dropout ,and Batch Normalization\n",
    "def define_baseline_model6():\n",
    "     model6 = Sequential()\n",
    "    model6.add(Conv2D(32, (3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same', input_shape = (32, 32, 3)))\n",
    "    model6.add(BatchNormalization())\n",
    "    model6.add(Conv2D(32, (3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
    "    model6.add(BatchNormalization())\n",
    "    model6.add(MaxPooling2D(2,2))\n",
    "    model6.add(Dropout(0.2))\n",
    "    model6.add(Conv2D(64, (3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
    "    model6.add(BatchNormalization())\n",
    "    model6.add(Conv2D(64, (3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
    "    model6.add(BatchNormalization())\n",
    "    model6.add(MaxPooling2D(2,2))\n",
    "    model6.add(Dropout(0.3))\n",
    "    model6.add(Conv2D(128, (3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
    "    model6.add(BatchNormalization())\n",
    "    model6.add(Conv2D(128, (3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
    "    model6.add(BatchNormalization())\n",
    "    model6.add(MaxPooling2D(2,2))\n",
    "    model6.add(Dropout(0.4))\n",
    "    model6.add(Flatten())\n",
    "    model6.add(Dense(128, activation = 'relu', kernel_initializer = 'he_uniform'))\n",
    "    model6.add(BatchNormalization())\n",
    "    model6.add(Dropout(0.5))\n",
    "    model6.add(Dense(10, activation = 'softmax'))\n",
    "    # compile the model\n",
    "    opt = keras.optimizers.Adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999)\n",
    "    model6.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return model6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model - Model7 - three VGG block with dropout and Batch Normalization\n",
    "def define_baseline_model7():\n",
    "    model7 = Sequential()\n",
    "    model7.add(Conv2D(32, (3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same', input_shape = (32, 32, 3)))\n",
    "    model7.add(BatchNormalization())\n",
    "    model7.add(Conv2D(32, (3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
    "    model7.add(BatchNormalization())\n",
    "    model7.add(MaxPooling2D(2,2))\n",
    "    model7.add(Dropout(0.2))\n",
    "    model7.add(Conv2D(64, (3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
    "    model7.add(BatchNormalization())\n",
    "    model7.add(Conv2D(64, (3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
    "    model7.add(BatchNormalization())\n",
    "    model7.add(MaxPooling2D(2,2))\n",
    "    model7.add(Dropout(0.3))\n",
    "    model7.add(Conv2D(128, (3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
    "    model7.add(BatchNormalization())\n",
    "    model7.add(Conv2D(128, (3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same' ))\n",
    "    model7.add(BatchNormalization())\n",
    "    model7.add(MaxPooling2D(2,2))\n",
    "    model7.add(Dropout(0.4))\n",
    "    model7.add(Flatten())\n",
    "    model7.add(Dense(128, activation = 'relu', kernel_initializer = 'he_uniform'))\n",
    "    model7.add(BatchNormalization())\n",
    "    model7.add(Dropout(0.5))\n",
    "    model7.add(Dense(10, activation = 'softmax'))\n",
    "    # compile the model\n",
    "    opt = keras.optimizers.Adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999)\n",
    "    model7.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return model7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_curves(history):\n",
    "    pyplot.subplot(211)\n",
    "    # plot loss\n",
    "    pyplot.title('Cross Entropy loss')\n",
    "    pyplot.plot(history.history['loss'], color = 'blue', label = 'train')\n",
    "    pyplot.plot(history.history['val_loss'], color = 'orange', label = 'validation')\n",
    "    # plot accuracy\n",
    "    pyplot.title('Classification accuracy')\n",
    "    pyplot.plot(history.history['accuracy'], color = 'blue', label = 'train')\n",
    "    pyplot.plot(history.history['val_accuracy'], color = 'orange', label = 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test set\n",
    "def evaluate():\n",
    "    # load the dataset\n",
    "    X_train_full, y_train_full, X_test, y_test = load_dataset()\n",
    "    # split the training into train and valid\n",
    "    X_train, X_valid, y_train, y_valid = train_valid_split()\n",
    "    # define the model\n",
    "    model = define_baseline_model7()\n",
    "    # apply image augmentation\n",
    "    datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "    # prepare iterator\n",
    "    it_train = datagen.flow(X_train_norm, y_train, batch_size=64)\n",
    "    # fit the model\n",
    "    steps = int(X_train.shape[0] / 64)\n",
    "    history = model.fit_generator(it_train, steps_per_epoch = steps, epochs = 100, validation_data = (X_valid_norm, y_valid), verbose = 1)\n",
    "    #history = model.fit(X_train_norm, y_train, epochs = 200, batch_size = 64, validation_data = (X_valid_norm, y_valid), verbose = 1)\n",
    "    # Evaluate the model\n",
    "    _, acc = model.evaluate(X_test, y_test, verbose = 0)\n",
    "    print('>%.3f' % (acc * 100.0))\n",
    "    # learning curves\n",
    "    summarize_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1 - One VGG block - accuracy on test set 62.74\n",
    "#### Model 2 - Two VGG block - accuracy on test set 69.92\n",
    "#### Model 3 - Three VGG bloc - accuracy on test set 74.70\n",
    "#### Model 4 - Three VGG block with Dropout - accuracy on test set 80.41\n",
    "#### Model 5 - Three VGG block with Dropout and weight decay - accuracy on test set 81.50\n",
    "#### Model 6 - Three VGG block with Dropout and Batch Normalization - accuracy on test set 84.89\n",
    "#### Model 7 - Three VGG block with dropout, Batch Normalization and Image augmentation - accuracy on test set 85.48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
